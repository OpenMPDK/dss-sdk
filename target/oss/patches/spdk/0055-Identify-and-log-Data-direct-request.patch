From 61e161d3ba81c1a0c72d5593ef291571460c5d07 Mon Sep 17 00:00:00 2001
From: Benixon Arul dhas <benixon.a@samsung.com>
Date: Thu, 11 Nov 2021 14:24:14 -0800
Subject: [PATCH 55/73] Identify and log Data direct request

---
 include/spdk/nvme_spec.h | 23 +++++++++++++++++
 lib/nvmf/rdma.c          | 65 ++++++++++++++++++++++++++++++++++++++++++++----
 2 files changed, 83 insertions(+), 5 deletions(-)

diff --git a/include/spdk/nvme_spec.h b/include/spdk/nvme_spec.h
index 74b6688..6f1d889 100644
--- a/include/spdk/nvme_spec.h
+++ b/include/spdk/nvme_spec.h
@@ -856,6 +856,28 @@ union spdk_nvme_feat_reservation_persistence {
 };
 SPDK_STATIC_ASSERT(sizeof(union spdk_nvme_feat_reservation_persistence) == 4, "Incorrect size");
 
+union spdk_nvme_feat_kv {
+	uint32_t raw;
+	struct {
+		uint32_t klen:8; //0's based keylen
+		uint32_t option:8;
+		uint32_t invalid_bytes:2;
+		uint32_t rsvd:14;
+	} put;
+	struct {
+		uint32_t klen:8; //0's based keylen
+		uint32_t option:8;
+		uint32_t rdd_cl_handle:16;// RDMA direct client handle
+	} get;
+	struct {
+		uint32_t klen:8; //0's based keylen
+		uint32_t option:8;
+		uint32_t rsvd:16;
+	} del;
+};
+
+SPDK_STATIC_ASSERT(sizeof(union spdk_nvme_feat_kv) == 4, "Incorrect size");
+
 union spdk_nvme_cmd_cdw10 {
 	uint32_t raw;
 	struct {
@@ -1028,6 +1050,7 @@ union spdk_nvme_cmd_cdw11 {
 	union spdk_nvme_feat_host_identifier feat_host_identifier;
 	union spdk_nvme_feat_reservation_notification_mask feat_rsv_notification_mask;
 	union spdk_nvme_feat_reservation_persistence feat_rsv_persistence;
+	union spdk_nvme_feat_kv feat_kv;
 
 	struct {
 		/* Attribute â€“ Integral Dataset for Read */
diff --git a/lib/nvmf/rdma.c b/lib/nvmf/rdma.c
index 032aa91..74a0a75 100644
--- a/lib/nvmf/rdma.c
+++ b/lib/nvmf/rdma.c
@@ -1482,6 +1482,16 @@ request_transfer_out(struct spdk_nvmf_request *req, int *data_posted)
 	assert(rqpair->current_recv_depth > 0);
 	rqpair->current_recv_depth--;
 
+	if(req->dreq->data_direct) {
+		*data_posted = 0;
+
+		rdma_req->num_outstanding_data_wr = 0;
+
+		/* +1 for the rsp wr */
+		rqpair->current_send_depth += num_outstanding_data_wr + 1;
+
+		return 0;
+	}
 	/* Build the response which consists of optional
 	 * RDMA WRITEs to transfer data, plus an RDMA SEND
 	 * containing the response.
@@ -1494,13 +1504,19 @@ request_transfer_out(struct spdk_nvmf_request *req, int *data_posted)
 		 */
 		rdma_req->num_outstanding_data_wr = 0;
 	} else if (req->xfer == SPDK_NVME_DATA_CONTROLLER_TO_HOST) {
-		//Reponse len set from cdw0 for retrieve
-		dfly_rdma_setup_data_transfer_out(rqpair, rqpair->device, rdma_req);
+		if(req->dreq->data_direct == 1) {
+			SPDK_NOTICELOG("Skipping data transfer for RDMA Direct");
+			rdma_req->num_outstanding_data_wr = 0;
+		} else {
+			//Reponse len set from cdw0 for retrieve
+			dfly_rdma_setup_data_transfer_out(rqpair, rqpair->device, rdma_req);
 
-		first = &rdma_req->data.wr;
-		*data_posted = 1;
-		num_outstanding_data_wr = rdma_req->num_outstanding_data_wr;
+			first = &rdma_req->data.wr;
+			*data_posted = 1;
+			num_outstanding_data_wr = rdma_req->num_outstanding_data_wr;
+		}
 	}
+
 	if (spdk_rdma_qp_queue_send_wrs(rqpair->rdma_qp, first)) {
 		STAILQ_INSERT_TAIL(&rqpair->poller->qpairs_pending_send, rqpair, send_link);
 	}
@@ -2262,6 +2278,45 @@ nvmf_rdma_request_parse_sgl(struct spdk_nvmf_rdma_transport *rtransport,
 			      req->iovcnt);
 
 		return 0;
+	} else if (sgl->generic.type == SPDK_NVME_SGL_TYPE_VENDOR_SPECIFIC &&
+		sgl->keyed.subtype == SPDK_NVME_SGL_SUBTYPE_ADDRESS /*RDMA Direct*/) {
+
+		SPDK_NOTICELOG("RDMA Data Direct request raddr:%p rkey %x len %d client handle %x\n",
+							sgl->address, sgl->keyed.key, sgl->keyed.length,
+							req->cmd->nvme_cmd.cdw11_bits.feat_kv.get.rdd_cl_handle);
+
+		//TODO: Validate command is only Get
+
+		dss_set_rdd_transfer(req->dreq);
+
+		length = sgl->keyed.length;
+
+		/*TODO: RDD - length validation to be based on the direct data connection*/
+
+		/* fill request length and populate iovs */
+		req->length = length;
+
+		/* DSS - dif insert or strip not supported */
+		assert(req->dif.dif_insert_or_strip == 0);
+
+		rc = nvmf_rdma_request_fill_iovs(rtransport, device, rdma_req, length);
+		if (spdk_unlikely(rc < 0)) {
+			if (rc == -EINVAL) {
+				SPDK_ERRLOG("SGL length exceeds the max I/O size\n");
+				rsp->status.sc = SPDK_NVME_SC_DATA_SGL_LENGTH_INVALID;
+				return -1;
+			}
+			/* No available buffers. Queue this request up. */
+			SPDK_DEBUGLOG(SPDK_LOG_RDMA, "No available large data buffers. Queueing request %p\n", rdma_req);
+			return 0;
+		}
+
+		/* backward compatible */
+		req->data = req->iov[0].iov_base;
+
+		SPDK_DEBUGLOG(SPDK_LOG_RDMA, "Request %p took %d buffer/s from central pool\n", rdma_req,
+			      req->iovcnt);
+		return 0;
 	}
 
 	SPDK_ERRLOG("Invalid NVMf I/O Command SGL:  Type 0x%x, Subtype 0x%x\n",
-- 
1.8.3.1

