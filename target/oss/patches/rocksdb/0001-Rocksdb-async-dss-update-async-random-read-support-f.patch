From 9a2dbe69b0f24237effd3e147d40e1fed13c141c Mon Sep 17 00:00:00 2001
From: Jian Liang <jian.l@ssi.samsung.com>
Date: Tue, 21 Jul 2020 02:06:35 -0700
Subject: [PATCH 01/18] Rocksdb async dss update * async random read support
 for linux * enable spdk/blobfs support * db_bench fullfill queue depth for
 async io when possible. * spdk malloc for async read buffer * spdk_mempool
 for async read buffer (disabled) * pipeline write option enabled. *
 spdk_cpumask option ( db_bench --spdk_cpumask=0x1 for core0, example)

---
 Makefile                        |   7 ++
 db/table_cache_request.cc       |   6 +-
 db/table_cache_request.h        |   2 +-
 include/rocksdb/env.h           |  12 +++-
 include/rocksdb/options.h       |   2 +-
 options/options.cc              |   4 +-
 src.mk                          |   1 +
 table/format.h                  |  63 ++++++++++++++++--
 table/format_request_context.cc |  24 +++++--
 tools/db_bench_tool.cc          | 142 ++++++++++++++++++++++++++--------------
 util/random_read_context.h      |  37 ++++++++++-
 util/threadpool_imp.cc          |   1 +
 12 files changed, 235 insertions(+), 66 deletions(-)

diff --git a/Makefile b/Makefile
index 0c6c4c0..fd13120 100644
--- a/Makefile
+++ b/Makefile
@@ -10,6 +10,7 @@ BASH_EXISTS := $(shell which bash)
 SHELL := $(shell which bash)
 
 CLEAN_FILES = # deliberately empty, so we can append below.
+#CFLAGS += ${EXTRA_CFLAGS} -fsanitize=address
 CFLAGS += ${EXTRA_CFLAGS}
 CXXFLAGS += ${EXTRA_CXXFLAGS}
 LDFLAGS += $(EXTRA_LDFLAGS)
@@ -90,6 +91,7 @@ endif
 # compile with -O2 if debug level is not 2
 ifneq ($(DEBUG_LEVEL), 2)
 OPT += -O2 -fno-omit-frame-pointer
+#OPT += -g -fno-omit-frame-pointer
 # Skip for archs that don't support -momit-leaf-frame-pointer
 ifeq (,$(shell $(CXX) -fsyntax-only -momit-leaf-frame-pointer -xc /dev/null 2>&1))
 OPT += -momit-leaf-frame-pointer
@@ -107,6 +109,8 @@ endif
 
 #-----------------------------------------------
 include src.mk
+SPDK_DIR ?= ../spdk
+SPDK_ROOT_DIR := $(abspath $(SPDK_DIR))
 
 AM_DEFAULT_VERBOSITY = 0
 
@@ -140,6 +144,9 @@ LDFLAGS += -lrados
 endif
 
 AM_LINK = $(AM_V_CCLD)$(CXX) $^ $(EXEC_LDFLAGS) -o $@ $(LDFLAGS) $(COVERAGEFLAGS)
+
+include $(SPDK_ROOT_DIR)/lib/rocksdb/spdk.rocksdb.mk
+
 # detect what platform we're building on
 dummy := $(shell (export ROCKSDB_ROOT="$(CURDIR)"; export PORTABLE="$(PORTABLE)"; "$(CURDIR)/build_tools/build_detect_platform" "$(CURDIR)/make_config.mk"))
 # this file is generated by the previous line to set build flags and sources
diff --git a/db/table_cache_request.cc b/db/table_cache_request.cc
index ad472ee..44be994 100644
--- a/db/table_cache_request.cc
+++ b/db/table_cache_request.cc
@@ -458,7 +458,7 @@ Status TableCacheGetContext::Get(TableCache* table_cache,
   return s;
 }
 
-Status TableCacheGetContext::RequestGet(const Callback& cb,
+Status TableCacheGetContext::RequestGet(Callback& cb,
                                         TableCache* table_cache, const ReadOptions& options,
                                         const InternalKeyComparator& internal_comparator,
                                         const FileDescriptor& fd, const Slice& k, GetContext* get_context,
@@ -480,6 +480,10 @@ Status TableCacheGetContext::RequestGet(const Callback& cb,
     TableReader* table_reader = nullptr;
 
     s = LookupTableReader(table_cache, options, fd, &handle, &table_reader);
+    if(s.IsNotFound()){
+        Callback empty_cb;
+        cb = empty_cb;
+    }
 
     if (s.ok() || s.IsNotFound()) {
       std::unique_ptr<TableCacheGetContext> context(new TableCacheGetContext(cb, 
diff --git a/db/table_cache_request.h b/db/table_cache_request.h
index 604136a..53e6578 100644
--- a/db/table_cache_request.h
+++ b/db/table_cache_request.h
@@ -604,7 +604,7 @@ class TableCacheGetContext : private AsyncStatusCapture {
                     GetContext* get_context, HistogramImpl* file_read_hist = nullptr,
                     bool skip_filters = false, int level = -1);
 
-  static Status RequestGet(const Callback& cb,
+  static Status RequestGet(Callback& cb,
                            TableCache* table_cache,
                            const ReadOptions& options,
                            const InternalKeyComparator& internal_comparator,
diff --git a/include/rocksdb/env.h b/include/rocksdb/env.h
index 394125f..6eaf5db 100644
--- a/include/rocksdb/env.h
+++ b/include/rocksdb/env.h
@@ -545,7 +545,8 @@ class RandomAccessFile {
   // supplied callback will be invoked on completion
   virtual Status RequestRead(const RandomAccessCallback& cb,
     uint64_t offset, size_t n, Slice* result, char* scratch) const {
-    return Status::NotSupported();
+    //return Status::NotSupported();
+    abort();
   }
 
   // Readahead the file starting from offset by n bytes for caching.
@@ -1168,6 +1169,15 @@ Status NewHdfsEnv(Env** hdfs_env, const std::string& fsname);
 // This is a factory method for TimedEnv defined in utilities/env_timed.cc.
 Env* NewTimedEnv(Env* base_env);
 
+// Returns a new environment that is used for SPDK environment.
+Env* NewSpdkEnv(Env* base_env, const std::string& fsname,
+		const std::string &cpumask, const std::string& confname,
+                const std::string& bdevname, uint64_t cache_size_in_mb);
+
+// Initializes a thread for SpdkEnv processing.
+void SpdkInitializeThread(void);
+
+
 }  // namespace rocksdb
 
 #endif  // STORAGE_ROCKSDB_INCLUDE_ENV_H_
diff --git a/include/rocksdb/options.h b/include/rocksdb/options.h
index 8fae953..869685f 100644
--- a/include/rocksdb/options.h
+++ b/include/rocksdb/options.h
@@ -787,7 +787,7 @@ struct DBOptions {
   // commit.
   //
   // Default: false
-  bool enable_pipelined_write = false;
+  bool enable_pipelined_write = true; //false;
 
   // If true, allow multi-writers to update mem tables in parallel.
   // Only some memtable_factory-s support concurrent writes; currently it
diff --git a/options/options.cc b/options/options.cc
index 37e1e57..1ae9dfd 100644
--- a/options/options.cc
+++ b/options/options.cc
@@ -615,7 +615,7 @@ ReadOptions::ReadOptions()
       prefix_same_as_start(false),
       pin_data(false),
       background_purge_on_iterator_cleanup(false),
-      ignore_range_deletions(false) {}
+      ignore_range_deletions(true) {}
 
 ReadOptions::ReadOptions(bool cksum, bool cache)
     : snapshot(nullptr),
@@ -631,6 +631,6 @@ ReadOptions::ReadOptions(bool cksum, bool cache)
       prefix_same_as_start(false),
       pin_data(false),
       background_purge_on_iterator_cleanup(false),
-      ignore_range_deletions(false) {}
+      ignore_range_deletions(true) {}
 
 }  // namespace rocksdb
diff --git a/src.mk b/src.mk
index d1cb262..3b28ec5 100644
--- a/src.mk
+++ b/src.mk
@@ -64,6 +64,7 @@ LIB_SOURCES =                                                   \
   env/env_chroot.cc                                             \
   env/env_hdfs.cc                                               \
   env/env_posix.cc                                              \
+  $(SPDK_ROOT_DIR)/lib/rocksdb/env_spdk.cc                      \
   env/io_posix.cc                                               \
   env/mock_env.cc                                               \
   memtable/alloc_tracker.cc                                     \
diff --git a/table/format.h b/table/format.h
index 40ef386..3a81fd7 100644
--- a/table/format.h
+++ b/table/format.h
@@ -10,6 +10,8 @@
 #pragma once
 #include <string>
 #include <stdint.h>
+#include <sched.h>
+
 #include "rocksdb/slice.h"
 #include "rocksdb/status.h"
 #include "rocksdb/options.h"
@@ -19,17 +21,27 @@
 #include "port/port.h"  // noexcept
 #include "table/persistent_cache_options.h"
 
+extern "C" {
+#include "spdk/env.h"
+}
+
 namespace rocksdb {
 
+//#define RDB_SPDK_MEMPOOL
+
 class Block;
 class RandomAccessFile;
 struct ReadOptions;
+#ifndef RDB_SPDK_MEMPOOL
+#else
+extern struct spdk_mempool * g_rdb_mempool;
+#endif
 
 extern bool ShouldReportDetailedTime(Env* env, Statistics* stats);
 
 // the length of the magic number in bytes.
 const int kMagicNumberLengthByte = 8;
-const uint32_t DefaultStackBufferSize = 5000;
+const uint32_t DefaultStackBufferSize = 8; //5000;
 
 // BlockHandle is a pointer to the extent of a file that stores a data
 // block or a meta block.
@@ -186,29 +198,72 @@ struct BlockContents {
   bool cachable;        // True iff data can be cached
   CompressionType compression_type;
   std::unique_ptr<char[]> allocation;
+  bool spdk_memory;
 
-  BlockContents() : cachable(false), compression_type(kNoCompression) {}
+  BlockContents() : cachable(false), compression_type(kNoCompression),
+    spdk_memory(false) {}
 
   BlockContents(const Slice& _data, bool _cachable,
                 CompressionType _compression_type)
-      : data(_data), cachable(_cachable), compression_type(_compression_type) {}
+      : data(_data), cachable(_cachable),
+      compression_type(_compression_type),
+      spdk_memory(false){}
 
   BlockContents(std::unique_ptr<char[]>&& _data, size_t _size, bool _cachable,
                 CompressionType _compression_type)
       : data(_data.get(), _size),
         cachable(_cachable),
         compression_type(_compression_type),
-        allocation(std::move(_data)) {}
+        allocation(std::move(_data)),spdk_memory(false){}
+
+  BlockContents(std::unique_ptr<char[]>&& _data, off_t offset, size_t _size, bool _cachable,
+                CompressionType _compression_type)
+      : data(_data.get() + offset, _size),
+        cachable(_cachable),
+        compression_type(_compression_type),
+        allocation(std::move(_data)),
+        spdk_memory(true){}
 
   BlockContents(BlockContents&& other) ROCKSDB_NOEXCEPT { *this = std::move(other); }
 
   BlockContents& operator=(BlockContents&& other) ROCKSDB_NOEXCEPT {
+    //printf("BlockContents::operator= cpu %d this %p, other %p data %p size %d cachable %d compression_type %d alloc %p\n",
+    //        sched_getcpu(), this, &other,
+    //        other.data.data(), other.data.size(), other.cachable,
+    //        other.compression_type, other.allocation.get());
+
     data = std::move(other.data);
     cachable = other.cachable;
     compression_type = other.compression_type;
     allocation = std::move(other.allocation);
+    spdk_memory = other.spdk_memory;
+
+    //printf("BlockContents::operator= done cpu %d this %p, other %p data %p size %d cachable %d compression_type %d alloc %p\n",
+    //        sched_getcpu(), this, &other,
+    //        other.data.data(), other.data.size(), other.cachable,
+    //        other.compression_type, other.allocation.get());
+
     return *this;
   }
+
+  ~BlockContents() {
+
+    if(spdk_memory){
+        void * alloc_buff = allocation.release();
+        //printf("~BlockContents: %p cpu %d spdk_free %p data %p size %d cachable %d compression_type %d alloc %p\n",
+        //        this, sched_getcpu(), alloc_buff, data.data(), data.size(), cachable, compression_type, allocation.get());
+
+        if(alloc_buff){
+#ifndef RDB_SPDK_MEMPOOL
+            spdk_free(alloc_buff);
+#else
+            spdk_mempool_put(g_rdb_mempool, alloc_buff);
+#endif
+            allocation.reset();
+        }
+    }
+
+  }
 };
 
 // Read the block identified by "handle" from "file".  On failure
diff --git a/table/format_request_context.cc b/table/format_request_context.cc
index b680d12..fd0749b 100644
--- a/table/format_request_context.cc
+++ b/table/format_request_context.cc
@@ -170,6 +170,8 @@ Status ReadBlockContentsContext::OnReadBlockContentsComplete(const Status& s,
   // then raw_slice is same as a result
   const Slice& slice = result_;
   size_t n = GetN();
+#define SPDK_BLOBSTORE_IO_UNIT_SIZE_MASK (512 - 1)
+  off_t buff_offset =  (handle_.offset() & SPDK_BLOBSTORE_IO_UNIT_SIZE_MASK);
 
   // We only allocate heap_buf_ if necessary
   char* used_buf = (heap_buf_) ? heap_buf_.get() : inclass_buf_;
@@ -188,21 +190,30 @@ Status ReadBlockContentsContext::OnReadBlockContentsComplete(const Status& s,
   rocksdb::CompressionType compression_type =
     static_cast<rocksdb::CompressionType>(slice.data()[n]);
 
-  if (decompression_requested_ && compression_type != kNoCompression) {
+    if (decompression_requested_ && compression_type != kNoCompression) {
     // compressed page, uncompress, update cache
     status = UncompressBlockContents(slice.data(), n, contents_,
                                      footer_->version(), compression_dict_,
                                      *ioptions_);
   } else if (slice.data() != used_buf) {
     // the slice content is not the buffer provided
-    *contents_ = BlockContents(Slice(slice.data(), n), false, compression_type);
+    if(client_cb_){
+        *contents_ = BlockContents(std::move(heap_buf_), buff_offset, n, true, compression_type);
+    }else{
+        *contents_ = BlockContents(Slice(slice.data(), n), false, compression_type);
+    }
   } else {
     // page is uncompressed, the buffer either stack or heap provided
     if (used_buf == inclass_buf_) {
       heap_buf_.reset(new char[n]);
       memcpy(heap_buf_.get(), inclass_buf_, n);
     }
-    *contents_ = BlockContents(std::move(heap_buf_), n, true, compression_type);
+
+    if(client_cb_){
+        *contents_ = BlockContents(std::move(heap_buf_), buff_offset, n, true, compression_type);
+    }else{
+        *contents_ = BlockContents(std::move(heap_buf_), n, true, compression_type);
+    }
   }
 
   if (status.ok() && read_options_->fill_cache &&
@@ -219,7 +230,10 @@ Status ReadBlockContentsContext::OnReadBlockContentsComplete(const Status& s,
 Status ReadBlockContentsContext::OnIoCompletion(const Status& status,
     const Slice& slice) {
   assert(status.async());
-  std::unique_ptr<ReadBlockContentsContext> self(this);
+
+  if(!client_cb_)
+    std::unique_ptr<ReadBlockContentsContext> self(this);
+
   Status s = OnReadBlockContentsComplete(status, slice);
   // In these classes OnIOComplletion is only invoked when async
   // simply enforce this
@@ -230,4 +244,4 @@ Status ReadBlockContentsContext::OnIoCompletion(const Status& status,
 
 
 }
-}
\ No newline at end of file
+}
diff --git a/tools/db_bench_tool.cc b/tools/db_bench_tool.cc
index c5f9fe3..6b248a1 100644
--- a/tools/db_bench_tool.cc
+++ b/tools/db_bench_tool.cc
@@ -724,6 +724,11 @@ static bool ValidateTableCacheNumshardbits(const char* flagname,
   return true;
 }
 DEFINE_int32(table_cache_numshardbits, 4, "");
+DEFINE_string(spdk, "", "Name of SPDK configuration file");
+DEFINE_string(spdk_bdev, "", "Name of SPDK blockdev to load");
+DEFINE_string(spdk_cpumask, "", "cpumask of SPDK");
+
+DEFINE_uint64(spdk_cache_size, 4096, "Size of SPDK filesystem cache (in MB)");
 
 #ifndef ROCKSDB_LITE
 DEFINE_string(env_uri, "", "URI for registry Env lookup. Mutually exclusive"
@@ -2035,9 +2040,11 @@ class Benchmark {
 #ifdef OS_WIN
   PTP_POOL                                 thread_pool_;
   std::shared_ptr<async::AsyncThreadPool>  async_tp_;
-  std::unique_ptr<AsyncBenchBase>          bench_func_;
+  //std::unique_ptr<AsyncBenchBase>          bench_func_;
 #endif
 
+  std::unique_ptr<AsyncBenchBase>          bench_func_;
+
   const SliceTransform* prefix_extractor_;
   DBWithColumnFamilies db_;
   std::vector<DBWithColumnFamilies> multi_dbs_;
@@ -2348,6 +2355,15 @@ class Benchmark {
       FLAGS_env = new ReportFileOpEnv(rocksdb::Env::Default());
     }
 
+    if (!FLAGS_spdk.empty()) {
+        FLAGS_env = rocksdb::NewSpdkEnv(rocksdb::Env::Default(), FLAGS_db, FLAGS_spdk_cpumask, FLAGS_spdk, FLAGS_spdk_bdev, FLAGS_spdk_cache_size);
+        if (FLAGS_env == NULL) {
+          fprintf(stderr, "Could not load SPDK blobfs - check that SPDK mkfs was run "
+                          "against block device %s.\n", FLAGS_spdk_bdev.c_str());
+          exit(1);
+        }
+      }
+
 #ifdef OS_WIN
     if (FLAGS_run_async) {
       const uint32_t maxThreads = 500;
@@ -2358,7 +2374,6 @@ class Benchmark {
       async_tp_ = FLAGS_env->CreateAsyncThreadPool(thread_pool_);
     }
 #endif
-
     if (FLAGS_prefix_size > FLAGS_key_size) {
       fprintf(stderr, "prefix size is larger than key size");
       exit(1);
@@ -2510,10 +2525,12 @@ void VerifyDBFromDB(std::string& truth_db_name) {
       exit(1);
     }
 
+#ifdef OS_WIN
     if (FLAGS_run_async) {
       open_options_.use_async_reads = true;
       open_options_.async_threadpool = std::move(async_tp_);
     }
+#endif
 
     Open(&open_options_);
     PrintHeader();
@@ -2640,11 +2657,13 @@ void VerifyDBFromDB(std::string& truth_db_name) {
       } else if (name == "readrandom") {
         method = &Benchmark::ReadRandom;
       } else if (name == "readrandomasync") {
+#ifndef OS_WIN
         bench_func_.reset(new ReadRandomAsync());
         if (!FLAGS_run_async) {
           fprintf(stdout, "run_async must be enabled\n");
           exit(1);
         }
+#endif
       } else if (name == "readrandomfast") {
         method = &Benchmark::ReadRandomFast;
       } else if (name == "multireadrandom") {
@@ -2662,11 +2681,13 @@ void VerifyDBFromDB(std::string& truth_db_name) {
       } else if (name == "seekrandom") {
         method = &Benchmark::SeekRandom;
       } else if (name == "seekrandomasync") {
+#ifdef OS_WIN
         bench_func_.reset(new SeekRandomAsync());
         if (!FLAGS_run_async) {
           fprintf(stdout, "run_async must be enabled\n");
           exit(1);
         }
+#endif
       }  else if (name == "seekrandomwhilewriting") {
         num_threads++;  // Add extra thread for writing
         method = &Benchmark::SeekRandomWhileWriting;
@@ -2802,7 +2823,7 @@ void VerifyDBFromDB(std::string& truth_db_name) {
           combined_stats.Report(name);
         }
       } else if(FLAGS_run_async) {
-#ifdef OS_WIN
+#ifndef OS_WIN
         if (num_repeat > 1) {
           printf("Running benchmark for %d times\n", num_repeat);
         }
@@ -2948,7 +2969,7 @@ void VerifyDBFromDB(std::string& truth_db_name) {
 
     return merge_stats;
   }
-#ifdef OS_WIN
+#ifndef OS_WIN
   // Will start standalone dispatcher threads
   // but I/O completion will run on a windows threadpool
   Stats RunBenchmarkAsync(int n, Slice name) {
@@ -2969,10 +2990,10 @@ void VerifyDBFromDB(std::string& truth_db_name) {
 
     std::vector<std::unique_ptr<ThreadState>> states;
     std::vector<std::unique_ptr<AsyncBenchBase>> benches;
-    std::vector<port::Thread>  threads;
+    //std::vector<port::Thread>  threads;
     states.resize(n);
     benches.resize(n);
-    threads.reserve(n);
+    //threads.reserve(n);
 
     for (int i = 0; i < n; i++) {
 
@@ -2982,8 +3003,9 @@ void VerifyDBFromDB(std::string& truth_db_name) {
 
       benches[i] = std::move(bench_func_->Clone());
       benches[i]->SetState(this, &shared, states[i].get());
-      port::Thread t(&AsyncBenchBase::Run, benches[i].get());
-      threads.push_back(std::move(t));
+      FLAGS_env->StartThread(AsyncBenchFunc, benches[i].get());
+      //port::Thread t(&AsyncBenchBase::Run, benches[i].get());
+      //threads.push_back(std::move(t));
     }
 
     shared.mu.Lock();
@@ -2998,9 +3020,9 @@ void VerifyDBFromDB(std::string& truth_db_name) {
     }
     shared.mu.Unlock();
 
-    for (auto& t : threads) {
-      t.join();
-    }
+    //for (auto& t : threads) {
+    //  t.join();
+    //}
 
     // Stats for some threads can be excluded.
     Stats merge_stats;
@@ -3863,7 +3885,9 @@ void VerifyDBFromDB(std::string& truth_db_name) {
       }
       if (!use_blob_db_) {
 #ifndef ROCKSDB_LITE
-        s = db_with_cfh->db->Write(write_options_, &batch);
+	//printf("DoWrite entries_per_batch_ %d batch count %d num_written %d bytes %ld\n", entries_per_batch_, batch.Count(), num_written, bytes);
+        //write_options_.no_slowdown = true;
+	s = db_with_cfh->db->Write(write_options_, &batch);
 #endif  //  ROCKSDB_LITE
       }
       thread->stats.FinishedOps(db_with_cfh, db_with_cfh->db,
@@ -4379,6 +4403,12 @@ void VerifyDBFromDB(std::string& truth_db_name) {
     }
   }
 
+  static void AsyncBenchFunc(void * ctx){
+    AsyncBenchBase * asyncBench = static_cast<AsyncBenchBase *>(ctx);
+    //static_cast<int>(throughput_ops_.size());
+    asyncBench->Run();
+  }
+
   struct RandomReadContext;
 
   // Faciliates a pool of memory allocations for the context
@@ -4395,7 +4425,7 @@ void VerifyDBFromDB(std::string& truth_db_name) {
 
     explicit
     ReadRandomAsync() :
-      options_(FLAGS_verify_checksum, true),
+      options_(FLAGS_verify_checksum, false),
       duration_(FLAGS_duration, FLAGS_reads),
       conc_io_ops_(FLAGS_conc_io_ops),
       read_(0),
@@ -4443,7 +4473,9 @@ void VerifyDBFromDB(std::string& truth_db_name) {
 
       CtxPtr ctx = AcquireInitContext();
       ctx->start_ = FLAGS_env->NowMicros();
-
+      std::string k_str;
+      ctx->key_.DecodeHex(&k_str);
+      //printf("RequestGet key %s, value size %d\n", k_str.c_str(), ctx->pinnable_val_.size());
       Status s;
       if (LIKELY(FLAGS_pin_slice == 1)) {
         s = async::DBImplGetContext::RequestGet(ctx->GetCallback(), ctx->db_with_cfh_->db, options_,
@@ -4466,38 +4498,41 @@ void VerifyDBFromDB(std::string& truth_db_name) {
     void Run() override {
       OnInitialized();
 
-      bool done = false;
-      int32_t in_flight = in_flight_;
-
-      {
-        std::unique_lock<std::mutex> l(m_);
-        while (!done || in_flight_ > 0) {
-
-          if (!done) {
-            while (in_flight_ < conc_io_ops_) {
-              Status s = RequestGet();
-              if (s.IsIOPending()) {
-                ++in_flight_;
-                ++in_flight;
-              } else {
-                // to properly account things that were done
-                ++in_flight;
-              }
-            }
-          }
+      //bool done = false;
+      //int32_t in_flight = in_flight_;
+      int32_t nr_ops = FLAGS_num;
+      int32_t nr_sync_io = 0;
+      //bool first_io = true;
+
+        //std::unique_lock<std::mutex> l(m_);
+        while (nr_ops) {
+
+            while (in_flight_.load(std::memory_order_relaxed) < conc_io_ops_) {
+                  //printf("Run RequestGet: in_flight_ %d nr_ops %d\n",
+                  //  in_flight_.load(std::memory_order_relaxed), nr_ops);
+                  Status s = RequestGet();
+                  //printf("Run: in_flight_ %d request s %s\n",
+                  //  in_flight_.load(std::memory_order_relaxed), s.ToString().c_str());
+                  if (s.IsIOPending()) {
+                    in_flight_.fetch_add(1, std::memory_order_relaxed);
+                  } else {
+                    // to properly account things that were done
+		        printf(" sync io %d!\n", ++ nr_sync_io);
+                  }
 
-          c_.wait(l);
+                  if(!(--nr_ops))
+                    break;
 
-          if (!done) {
-            assert(in_flight >= in_flight_);
-            auto diff = in_flight - in_flight_;
-            if (diff > 0) {
-              done = duration_.Done(diff);
             }
-          }
-          in_flight = in_flight_;
+
+            if(in_flight_.load(std::memory_order_relaxed))
+                usleep(1000);
         }
-      }
+
+       while(in_flight_.load(std::memory_order_relaxed))
+        usleep(100);
+
+       //     c_.wait(l);
 
       char msg[100];
       snprintf(msg, sizeof(msg), "(%" PRIu64 " of %" PRIu64 " found)\n",
@@ -4532,10 +4567,11 @@ void VerifyDBFromDB(std::string& truth_db_name) {
       }
 
       {
-        std::lock_guard<std::mutex> l(m_);
-        --in_flight_;
+        //std::lock_guard<std::mutex> l(m_);
+        in_flight_.fetch_sub(1, std::memory_order_relaxed);
       }
-      c_.notify_one();
+      //printf("ReadComplete in_flight_ %d\n", in_flight_.load(std::memory_order_relaxed));
+      //c_.notify_one();
     }
 
     ReadRandomAsync(const ReadRandomAsync&) :
@@ -4554,7 +4590,7 @@ void VerifyDBFromDB(std::string& truth_db_name) {
     std::atomic<int64_t>     bytes_;
     std::mutex              m_;
     std::condition_variable c_;
-    int32_t                 in_flight_;
+    std::atomic<int32_t>     in_flight_;
     uint64_t                start_;
   };
 
@@ -4593,6 +4629,7 @@ void VerifyDBFromDB(std::string& truth_db_name) {
         bench_->bytes_.fetch_add(key_.size() +
           (FLAGS_pin_slice == 1 ? pinnable_val_.size() : value_.size()),
           std::memory_order_relaxed);
+
       } else if (!status.IsNotFound()) {
         fprintf(stderr, "Get returned an error: %s\n",
           status.ToString().c_str());
@@ -6038,8 +6075,17 @@ int db_bench_tool(int argc, char** argv) {
     FLAGS_stats_interval = 1000;
   }
 
-  rocksdb::Benchmark benchmark;
-  benchmark.Run();
+
+  // Allocate the Benchmark off the heap, so that we can explicitly delete it
+  //  before the SpdkEnv is deleted.
+  rocksdb::Benchmark *benchmark = new rocksdb::Benchmark;
+  benchmark->Run();
+  delete benchmark;
+
+  if (!FLAGS_spdk.empty()) {
+      delete FLAGS_env;
+  }
+
   return 0;
 }
 }  // namespace rocksdb
diff --git a/util/random_read_context.h b/util/random_read_context.h
index 5fa3d36..37e7050 100644
--- a/util/random_read_context.h
+++ b/util/random_read_context.h
@@ -19,6 +19,11 @@
 #include "util/stop_watch.h"
 
 #include <type_traits>
+#include <sched.h>
+
+extern "C" {
+#include "spdk/env.h"
+}
 
 namespace rocksdb {
 
@@ -27,6 +32,10 @@ class HistogramImpl;
 class RandomAccessFile;
 class RandomAccessFileReader;
 class Statistics;
+#ifndef RDB_SPDK_MEMPOOL
+#else
+extern struct spdk_mempool * g_rdb_mempool ;
+#endif
 
 namespace async {
 
@@ -425,12 +434,14 @@ class ReadBlockContentsContext {
     cache_options_(&cache_options),
     contents_(contents),
     is_read_block_(false) {
+    //printf("ReadBlockContentsContext %p created\n", this);
   }
 
   ~ReadBlockContentsContext() {
     if (is_read_block_) {
       GetReadBlock()->~ReadBlockContext();
     }
+    //printf("~ReadBlockContentsContext %p\n", this);
   }
 
   ReadBlockContentsContext(const ReadBlockContentsContext&) = delete;
@@ -539,10 +550,30 @@ class ReadBlockContentsContext {
         n + kBlockTrailerSize < DefaultStackBufferSize) {
       used_buf = inclass_buf_;
     } else {
-      heap_buf_.reset(new char[n + kBlockTrailerSize]);
-      used_buf = heap_buf_.get();
+      if(client_cb_){
+#define SPDK_BLOBSTORE_IO_UNIT_SIZE 512
+          int lba_size = SPDK_BLOBSTORE_IO_UNIT_SIZE;
+          int spdk_buffer_size = (((n + kBlockTrailerSize + lba_size - 1) / lba_size) + 1) * lba_size;
+
+	#ifndef RDB_SPDK_MEMPOOL
+	  void * buf = spdk_malloc( spdk_buffer_size, SPDK_BLOBSTORE_IO_UNIT_SIZE, NULL,
+					  SPDK_ENV_SOCKET_ID_ANY, SPDK_MALLOC_DMA|SPDK_MALLOC_SHARE);
+	#else
+	  void * buf = spdk_mempool_get(g_rdb_mempool);
+	#endif
+
+          void * prev_buf = heap_buf_.get();
+	  if(!buf)
+		abort();
+          heap_buf_.reset((char *)buf);
+          used_buf = heap_buf_.get();
+      }else{
+        heap_buf_.reset(new char[n + kBlockTrailerSize]);
+        used_buf = heap_buf_.get();
+      }
     }
-
+    //printf("ConstructReadBlockContext decomp %d, DefaultStackBufferSize %d n %d, used_buf %p, used_bufkBlockTrailerSize %d\n",
+//	decompression_requested_, DefaultStackBufferSize, n, used_buf, kBlockTrailerSize);
     new (&read_block_) ReadBlockContext(ReadBlockContext::ReadBlockCallback(),
                                         reader,
                                         footer_->checksum(), read_options_->verify_checksums, handle_,
diff --git a/util/threadpool_imp.cc b/util/threadpool_imp.cc
index aa40ab9..07f9345 100644
--- a/util/threadpool_imp.cc
+++ b/util/threadpool_imp.cc
@@ -250,6 +250,7 @@ void* ThreadPoolImpl::Impl::BGThreadWrapper(void* arg) {
   BGThreadMetadata* meta = reinterpret_cast<BGThreadMetadata*>(arg);
   size_t thread_id = meta->thread_id_;
   ThreadPoolImpl::Impl* tp = meta->thread_pool_;
+   SpdkInitializeThread();
 #ifdef ROCKSDB_USING_THREAD_STATUS
   // for thread-status
   ThreadStatusUtil::RegisterThread(
-- 
1.8.3.1

